# -*- coding: utf-8 -*-
"""train_dht22_data_time_series

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1rnmI-7BncSd3-KpxLJ9n4l5pJzb5bBST
"""

# =========================
# 1. IMPORT LIBS
# =========================
import numpy as np
import pandas as pd
import os
from sklearn.preprocessing import StandardScaler
from sklearn.cluster import KMeans
from sklearn.model_selection import train_test_split

import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense, Dropout, Bidirectional

# =========================
# 2. HYPERPARAMS
# =========================
WINDOW_MINUTES = 60      # dùng 60 phút quá khứ
HORIZON_MINUTES = 15     # dự báo 15 phút tới
N_CLUSTERS = 6           # 6 trạng thái thời tiết

RANDOM_STATE = 42

# =========================
# 3. LOAD & PREPROCESS DATA
# =========================
BASE_DIR = os.path.dirname(os.path.abspath(__file__))
csv_path = os.path.join(BASE_DIR,"..","DHT22_DATA","dht22_clean_processed.csv")
df = pd.read_csv(csv_path)

df["datetime"] = pd.to_datetime(df["datetime"])
df = df.sort_values("datetime")

# Resample 1 phút + nội suy
df_resampled = (
    df.set_index("datetime")
      .resample("1min")
      .mean()
      .interpolate()
)

# Làm mượt humidity với rolling 3 điểm
df_resampled["humidity"] = (
    df_resampled["humidity"]
      .rolling(3, center=True)
      .mean()
)

# QUAN TRỌNG: drop NaN sau rolling để sạch hoàn toàn
df_resampled = df_resampled.dropna(subset=["temperature", "humidity"])

# Chỉ giữ 2 feature chính
data = df_resampled[["temperature", "humidity"]].copy()

# Chuẩn hoá (StandardScaler)
scaler = StandardScaler()
data_scaled = scaler.fit_transform(data.values)

print("Data resampled shape:", data_scaled.shape)
print("Time index range:", df_resampled.index.min(), "->", df_resampled.index.max())

# =========================
# 4. TẠO SEQUENCE (WINDOW 60P -> TARGET 15P SAU)
# =========================
def build_sequences(data_array, window_size, horizon):
    X, y, window_start_idx = [], [], []
    n = len(data_array)
    for i in range(n - window_size - horizon + 1):
        x_i = data_array[i : i + window_size]            # 60 phút quá khứ
        y_i = data_array[i + window_size + horizon - 1]  # điểm 15 phút sau cuối window
        X.append(x_i)
        y.append(y_i)
        window_start_idx.append(i)
    return np.array(X), np.array(y), np.array(window_start_idx)

WINDOW_SIZE = WINDOW_MINUTES
HORIZON = HORIZON_MINUTES

X, y, window_idx = build_sequences(data_scaled, WINDOW_SIZE, HORIZON)

print("X shape (samples, timesteps, features):", X.shape)
print("y shape (samples, features):", y.shape)

# =========================
# 5. TRÍCH FEATURES CHO CLUSTERING
# =========================
def extract_features_for_clustering(X_seq):
    feats = []
    for seq in X_seq:
        temp = seq[:, 0]
        humid = seq[:, 1]
        f = [
            temp.mean(),          # mean temp
            temp.std(),           # std temp
            humid.mean(),         # mean humid
            humid.std(),          # std humid
            temp[-1] - temp[0],   # trend temp
            humid[-1] - humid[0], # trend humid
        ]
        feats.append(f)
    return np.array(feats)

X_feats = extract_features_for_clustering(X)
print("Feature for clustering shape:", X_feats.shape)
print("NaN in X_feats? ->", np.isnan(X_feats).any())

# =========================
# 6. CLUSTERING 6 TRẠNG THÁI THỜI TIẾT
# =========================
kmeans = KMeans(
    n_clusters=N_CLUSTERS,
    random_state=RANDOM_STATE,
    n_init=10
)
cluster_labels = kmeans.fit_predict(X_feats)

print("Cluster labels (0..5):", np.unique(cluster_labels))

cluster_df = pd.DataFrame({
    "window_start_idx": window_idx,
    "cluster_label": cluster_labels
})
print(cluster_df.head())

# =========================
# 7. TRAIN / TEST SPLIT CHO LSTM
# =========================
X_train, X_test, y_train, y_test, cl_train, cl_test = train_test_split(
    X, y, cluster_labels,
    test_size=0.2,
    shuffle=False
)

print("Train shape:", X_train.shape, y_train.shape)
print("Test shape :", X_test.shape,  y_test.shape)

# =========================
# 8. BUILD LSTM MODEL
# =========================
n_timesteps = X_train.shape[1]
n_features = X_train.shape[2]
output_size = y_train.shape[1]

model = Sequential([
    tf.keras.Input(shape=(n_timesteps, n_features)),
    Bidirectional(LSTM(64, return_sequences=False)),
    Dropout(0.2),
    Dense(32, activation="relu"),
    Dense(output_size)
])

model.compile(
    loss="mse",
    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),
    metrics=["mae"]
)

model.summary()

# =========================
# 9. TRAIN MODEL (EARLY STOPPING)
# =========================
callback = tf.keras.callbacks.EarlyStopping(
    monitor="val_loss",
    patience=5,
    restore_best_weights=True
)

history = model.fit(
    X_train, y_train,
    validation_data=(X_test, y_test),
    epochs=100,
    batch_size=32,
    callbacks=[callback],
    verbose=1
)

# =========================
# 10. EVALUATE & DỰ BÁO
# =========================
y_pred_test = model.predict(X_test)

def inverse_scale(scaled_values):
    return scaler.inverse_transform(scaled_values)

y_test_unscaled = inverse_scale(y_test)
y_pred_unscaled = inverse_scale(y_pred_test)

print("Ví dụ 5 dòng dự báo (temp, humid) 15p tới:")
for i in range(5):
    print(f"Thực tế : {y_test_unscaled[i]}")
    print(f"Dự báo : {y_pred_unscaled[i]}")
    print("---")

# =========================
# 11. MAPPING CLUSTER -> TEXT LABEL
# =========================
CLUSTER_TEXT = {
    0: "Trời ổn định",
    1: "Nhiệt độ tăng, có xu hướng nóng hơn",
    2: "Nhiệt độ giảm, trời mát hơn",
    3: "Độ ẩm tăng, có khả năng trời sắp mưa",
    4: "Độ ẩm giảm, trời khô ráo hơn",
    5: "Biến động mạnh, thời tiết thất thường"
}

def cluster_to_text(cluster_id):
    return CLUSTER_TEXT.get(int(cluster_id), "Trạng thái không xác định")

for i in range(5):
    c_id = cl_test[i]
    print("Cluster:", c_id, "->", cluster_to_text(c_id))

# =========================
# 12. HÀM DÙNG REALTIME
# =========================
def forecast_and_cluster_from_raw_window(last_60min_df):
    arr = last_60min_df[["temperature", "humidity"]].values
    arr_scaled = scaler.transform(arr)
    x_input = np.expand_dims(arr_scaled, axis=0)  # (1, 60, 2)

    y_pred_scaled = model.predict(x_input)
    y_pred_real = inverse_scale(y_pred_scaled)[0]

    feats = extract_features_for_clustering(x_input)[0:1]
    cluster_id = kmeans.predict(feats)[0]
    cluster_text = cluster_to_text(cluster_id)

    return y_pred_real, cluster_id, cluster_text

# =========================
# 13. DEMO GIẢ LẬP REALTIME
# =========================
last_60 = df_resampled[["temperature", "humidity"]].iloc[-WINDOW_SIZE:]

y_future, c_id, c_text = forecast_and_cluster_from_raw_window(last_60)
print("Dự báo 15 phút nữa (temp, humid):", y_future)
print("Cluster hiện tại:", c_id, "->", c_text)

# ========= SAVE MODEL ==========
model.save("models/lstm_model.h5")

import pickle
with open("models/scaler.pkl", "wb") as f:
    pickle.dump(scaler, f)

with open("models/kmeans.pkl", "wb") as f:
    pickle.dump(kmeans, f)

print("Saved lstm_model.h5, scaler.pkl, kmeans.pkl into folder MODELS.")